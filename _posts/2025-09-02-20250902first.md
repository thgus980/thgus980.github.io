---
layout: single
title:  "[2025-09-02] 20250902 개발일지"
categories: devlog
toc: true
---

## 녹음파일 기반 회의록 작성

### 1. GPT로 녹취록 교정하기
- GPT 첫 호출 시, 프롬프트를 추가 작성(2번)해서 STT 오류 교정할 수 있도록 함
  ```python
  prompt = f"""
            다음은 {meeting_json['meeting_info']['total_speakers']}명이 참석한 회의 내용입니다.

            회의 정보:
            - 시간: {meeting_json['meeting_info']['duration_minutes']}분
            - 발언 수: {meeting_json['meeting_info']['total_statements']}개

            발언 내용:
            {timeline_text}

            위 내용을 바탕으로 아래의 조건을 고려하여, 다음 마크다운 형식으로 전문적인 회의록을 작성해주세요.
            1. 한국어로 전문적이고 구체적으로 작성해주세요.
            2. 주어진 발언 내용은 STT로 작성된 결과이므로, 이 중에 오류가 있는 부분이 있다면 수정하여 회의록 내용을 작성해주세요.
            3. 사실 기반으로 작성해주세요. 모르는 내용을 덧붙이지 마세요.
            4. 문장은 '-다'로 끝나는 것이 아닌 단어나 '-했음, -함' 등으로 명사형으로 끝내주세요.

            # {meeting_title}

            ## 회의 개요
            - **작성 일자**: {meeting_json['meeting_info']['date']}
            - **참석인원**: {meeting_json['meeting_info']['total_speakers']}명
            - **회의 시간**: {meeting_json['meeting_info']['duration_minutes']}분

            ## 주요 논의사항
            [핵심 안건 3-5개]

            ## 화자별 주요 발언
            [각 화자의 핵심 발언 요약]

            ## 결정사항
            [구체적인 결정 내용]
        """
  ```

### 2. 화자 매칭이 필요한 이유
- 문제 상황: 입력 데이터 2개
  - Whisper: [안녕하세요] 2-4초
  - pyannote: [화자1] 1-5초
- 목표: 둘을 합쳐서 -> 화자1이 2-4초에 '안녕하세요'라고 말함
  ```python
  def match_transcription_with_speakers(self, transcription, speaker_segments):
  """전사 결과와 화자 정보 매칭"""
  print("🔗 전사 결과와 화자 정보 매칭 중...")
  
  def find_dominant_speaker(start_time, end_time, speaker_segments):
      overlaps = {}
      for seg in speaker_segments:
          overlap_start = max(start_time, seg['start'])
          overlap_end = min(end_time, seg['end'])
          
          if overlap_start < overlap_end:
              overlap_duration = overlap_end - overlap_start
              speaker = seg['speaker']
              
              if speaker not in overlaps:
                  overlaps[speaker] = 0
              overlaps[speaker] += overlap_duration
      
      if overlaps:
          dominant_speaker = max(overlaps.items(), key=lambda x: x[1])[0]
          return dominant_speaker
      return "Unknown"
  
  matched_segments = []
  speaker_mapping = {}
  
  for segment in transcription.segments:
      start_time = segment.start
      end_time = segment.end
      text = segment.text.strip()
      
      raw_speaker = find_dominant_speaker(start_time, end_time, speaker_segments)
      
      if raw_speaker not in speaker_mapping:
          speaker_index = len(speaker_mapping)
          speaker_mapping[raw_speaker] = f"화자 {chr(65 + speaker_index)}"
      
      speaker_name = speaker_mapping[raw_speaker]
      
      matched_segments.append({
          'start': round(start_time, 1),
          'end': round(end_time, 1),
          'duration': round(end_time - start_time, 1),
          'speaker': speaker_name,
          'text': text,
          'confidence': round(getattr(segment, 'avg_logprob', 0), 3)
      })
  
  print(f"✅ 매칭 완료: {len(speaker_mapping)}명의 화자로 정리")
  return matched_segments
  ```
