---
layout: single
title:  "[2025-05-11] 20250511 개발일지"
categories: devlog
toc: true
---

## 도서명: RAG 시스템 구축을 위한 랭체인 실전 가이드

### Github Repository
private repository

### 1. 사용자의 쿼리를 재해석해 검색하는 MultiQueryRetriever
1. RAG는 사용자의 질문과 가장 유사한 청크를 바탕으로 근거 자료를 찾는 것이 핵심
2. 질문 문장이 벡터 DB 내 청크들과 유사하지 않은 경우가 있을 수 있음 -> 사용자 질문을 여러 버전으로 만들어 벡터 DB 내 검색이 원활하게끔 하자
3. 예) 생일 휴가는 며칠인가요? (본 질문) -> 생일과 관련된 복지는 무엇이 있나요?, 기념일 휴가의 종류는 무엇인가요?
4. LLM은 Retriever에 주어진 질문의 의도를 파악하고, 여러 버전의 질문을 생성하여 검색 결과가 더욱 풍부해지도록 촉진

### 2. 문서를 여러 벡터로 재해석하는 MultiVectorRetriever
1. 문서의 벡터를 재가공하여 검색 품질을 향상
2. 상위 청크를 하위 청크로 쪼갠다
3. 사용자의 질문과 유사한 문서를 찾을 때, 하위 청크를 검색하고 이를 기반으로 상위 청크를 호출 -> 벡터 DB를 기반으로 하위 유사 청크를 검색하고, 해당 청크들의 문서 id를 타고 올라가 상위 청크를 반환

### 3. 컨텍스트를 재정렬하는 Long-Context Reorder
1. 컨텍스트가 길어져도 정보가 매우 앞쪽이나 매우 뒤쪽에 위치한다면 모델의 컨텍스트 윈도우 이해력이 높다.
2. 사용자의 질문과 유사한 근거 문서를 여러 개 추출한 후, 중요한 순서대로 컨텍스트의 맨 앞쪽과 맨 뒤쪽에 배치하여 답변의 정확도를 향상하는 원리

### 4. 랭체인을 표현하는 언이, LCEL
1. LCEL? Langchain Expression Language, 랭체인 표현 형식
2. LCEL 기반 기본 체인 구성: Prompt Template -> LLM -> Output Parser
3. LCEL은 효율적인 코드 관리와 쉬운 코드 작성이 가능하도록 돕는다. (LCEL로 프롬프트 템플릿-LLM-출력 파서 연결)
4. 파이프 오퍼레이터 | 기호를 통해 모듈을 연결
5. stream() 함수를 실행하면 사람이 타이핑하듯이 답변을 차례차례 출력하도록 만드는 스트리밍 기능 가능
6. 여러 개 API를 요청하고 받는 batch() -> 여러 대상에 대해서 같은 작업을 여러번 수행해야 할 때/ 5개의 문장을 batch()를 이용하여 한꺼번에 번역한 경우나 1개 문장만 번역한 경우나 모두 동일한 시간이 걸린다.

### 5. 기본적인 Q&A 체인 구성 - RAG의 작동 순서도
1. Document Loader: 문서 로드
2. Text Splitter: 문서 분할
3. Embedding Models: 텍스트 임베딩
4. Vector Stores: 임베딩 저장
5. Retriever: 유사 문장 검색
6. 위의 결과물 + 사용자 질문 -> LLM에 던져줌

### 6. RAG 시스템 구축 시 결정해야할 요소 및 적절한 모듈
1. 모델의 종류: GPT를 API 형태로
2. Document Loader: PDF Loader
3. Text Splitter: RecursiveCharacterTextSplitter
4. 임베딩 모델: OpenAI의 text-embedding-3-small
5. 벡터 스토어: Chroma
6. Retriever: Chroma를 벡터 스토어로 설정했기 때문에, 벡터 스토어 기반 검색기를 활용할 수 있음
7. Chain: LECL을 기반으로 앞선 구성요소들을 하나로 묶어 구성
8. 정리: 가장 먼저 Chain으로 사용자의 질문을 입력 받으면, 벡터 데이터베이스에서 유사 문장을 검색하기 위해 Retriever에 연결 한다. 그리고 그 결과물을 context의 Value로 지정한다. 사용자의 질문읜 RunnablePassthrough()를 통해 어떤 수정도 거치지 않고 그대로 qeustion의 Value로 전달된다. 이렇게 하나의 Dictionary 객체를 완성하면, 이것을 그대로 사전에 정의한 프롬프트 템플릿에 전달한다. 사전에 정의한 프롬프트 템플릿은 매개변수로 context와 question을 갖고 있었는데, 앞서 사용자의 질문을 바탕으로 완성한 Dictionary에 이 매개변수들의 값이 저장되어 있으므로 이것이 그대로 프롬프트를 완성하는 것에 활용된다. 완성된 프롬프트는 LLM에 전달되고, 사용자의 질문과 검색 결과물을 종합하여 작성한 LLM의 답변은 StrOutputParser()를 거쳐 문자열의 형태로 출력된다.

### 7. Memory 기능 구축 - 챗봇의 기억력
1. 사용자의 질문이 들어오면 그동한 적재한 채팅 히스토리와 통합하는 작업을 거친다. 이때 LLM에게 주어지는 프롬프트는 '채팅 기록과 최신 사용자 질문을 통합하여 채팅 기록 없이 이해 가능한 독립형 질문을 만들어라'이다.
2. 이렇게 채팅 히스토리와 사용자 질문을 통합한 후에는 기존 RAG와 동일한 과정을 거쳐 답변을 생성한다. Retriever를 통해 통합된 질문과 유사한 문장을 검색해내고, 이를 Q&A 프롬프트 내에 맥락으로 주입하여 LLM에게 답변할 수 있도록 힌트를 제공한다.
3. 최종적으로 LLM은 채팅 히스토리와 사용자의 질문, 그리고 답변을 위한 힌트 컨텍스트를 모두 갖춰, 보다 정확한 답변이 가능하다.

### 참고
1. 사용자가 프롬프트에 던진 질문과 유사도가 높은 문서를 추출할 때 chunk 단위(글 덩어리)로 비교하는데, 이때 chunk는 글자 수 기준으로 분할 ( 예. 500자 ), 문맥을 파악해서 문맥이 바뀌는 지점을 기준으로 분할, 토큰 단위로 분할 등 다양하게 지정 가능하다.
2. 랭체인에서 지원하는 RecursiveCharacterTextSplitter(글자 수 분할), SemanticChunker(문맥을 파악해 분할), TokenTextSplitter(토큰 단위 분할)을 import 하여 구현 가능하다.
3. ```python
   # 청크 길이 500
   text_splitter=RecursiveCharacterTextSpliter(
     chunk_size=500
   )
   ```
4. RAG(Retrieval-Augmented Generation) 시스템에서 **토큰(token)**은 언어 모델이 텍스트를 처리할 때 사용하는 기본 단위입니다. 토큰은 일반적으로 단어, 부분 단어, 또는 심지어 구두점, 공백 등으로 분할된 텍스트 조각을 의미합니다. 영어의 경우 한 단어가 하나의 토큰이 될 수도 있고, 긴 단어는 여러 토큰으로 분해될 수도 있습니다. 한글이나 다른 언어도 마찬가지로, 한 글자 또는 자주 등장하는 단어가 토큰이 될 수 있습니다.