---
layout: single
title:  "[2025-12-07] 20251207 개발일지"
categories: devlog
toc: true
---

## AWS 인프라 구축 단계

### In-house (외부 LLM 사용 X)
- 1단계: 기반 인프라 구성  
VPC 설정 및 프라이빗/퍼블릭 서브넷 분리  
NAT Gateway 구성 (프라이빗 서브넷의 외부 통신용)  
Security Group으로 계층별 접근 제어  
- 2단계: 데이터 저장소 구축
RDS로 HR DB 구성 또는 기존 온프레미스 DB와 Direct Connect/VPN 연결  
S3에 HR 문서 저장 (취업규칙, 인사제도 가이드 등)  
EFS 또는 S3로 Llama 모델 파일 저장  
- 3단계: Llama 모델 서빙 인프라
EC2 GPU 인스턴스 (g5.xlarge 이상, 모델 크기에 따라 선택)  
Llama 2 7B: g5.xlarge~g5.2xlarge  
Llama 2 13B 이상: g5.4xlarge 이상 또는 p3/p4 인스턴스  
vLLM, TGI(Text Generation Inference), FastAPI로 모델 서빙 구축  
Auto Scaling Group으로 트래픽에 따른 인스턴스 확장  
Application Load Balancer로 모델 서빙 엔드포인트 분산  
- 4단계: 벡터 DB 및 RAG 파이프라인
OpenSearch 클러스터 구축 (벡터 검색용) 또는 EC2에 Milvus, Qdrant 등 오픈소스 벡터 DB 직접 구축  
임베딩 모델 서빙 (sentence-transformers 등)  
별도 EC2 또는 모델 서빙 인스턴스와 공유  
Lambda 또는 ECS로 문서 임베딩 파이프라인 구축  
- 5단계: 애플리케이션 레이어
ECS/EKS로 챗봇 애플리케이션 컨테이너 배포  
RAG 오케스트레이션 로직  
DB 쿼리 처리  
Llama API 호출  
API Gateway 또는 ALB로 API 엔드포인트 제공  
ElastiCache (Redis)로 세션 관리 및 캐싱  
- 6단계: MLOps 파이프라인
SageMaker 또는 EC2로 모델 파인튜닝 환경 구축  
S3에 학습 데이터 및 모델 버전 관리  
ECR에 커스텀 Docker 이미지 저장  
CodePipeline으로 CI/CD 구성  
- 7단계: 프론트엔드
S3 + CloudFront로 웹 UI 배포 또는 ECS/EKS에 프론트엔드 컨테이너 배포  
- 8단계: 보안 및 모니터링
IAM 역할 및 정책 설정  
Secrets Manager로 DB 자격증명 관리  
CloudWatch로 GPU 사용률, 응답시간 모니터링  
Prometheus + Grafana (EKS 사용 시)  
AWS WAF로 API 보호  
